@Authors - Venkat Gandharv Thanniru and Aum Bhanderi
@Version - 1.0


%--------------LEXER---------------

% In Progress


import ply.lex as lex
 
 # List of token names.   This is always required
 tokens = (
    'NUMBER',
    'STRING',
    'ID',
    'INCRMNT',
    'DECRMNT',
    'BOOLEQL',
    'GTEQL',
    'LTEQL',
    'NOTEQL',
    'OR',
    'AND',
    'NOT',
    'IF',
    'WHILE',
    'FOR',
    'VARIABLE',
    'ELSEIF',
    'ELSE',
    'PRINT',
    'TRUE',
    'FALSE'
 )
 
 reserved = {
    'if':'IF',
    'while':'WHILE',
    'for':'FOR',
    'var':'VARIABLE',
    'elif':'ELSEIF',
    'else':'ELSE',
    'print':'PRINT',
    'true':'TRUE',
    'false':'FALSE'

}

# Regular expression rules for simple tokens 
// The names given below are not exactly what we will be using in the future. This is just foe reference and changes will be made accordingly 
// once the parse tree s finalised. 

 t_PLUS    = r'\+'
 t_MINUS   = r'-'
 t_TIMES   = r'\*'
 t_DIVIDE  = r'/'
 t_LPAREN  = r'\('
 t_RPAREN  = r'\)'
 
 
 # A regular expression rule with some action code
 def t_NUMBER(t):
     r'\d+'
     t.value = int(t.value)    
     return t
     
def t_STRING(t):
    r'"(.*?)"'
    return t

def t_ID(t):
    r'[a-zA-Z_][a-zA-Z_0-9]*'
    t.type = reserved.get(t.value,'ID')    # Check for reserved words
    return t
 
 # Define a rule so we can track line numbers
 def t_newline(t):
     r'\n+'
     t.lexer.lineno += len(t.value)
 
 # A string containing ignored characters (spaces and tabs)
 t_ignore  = ' \t'
 
 # Error handling rule
 def t_error(t):
     print("Illegal character '%s'" % t.value[0])
     t.lexer.skip(1)
 
 # Build the lexer
 lexer = lex.lex()
